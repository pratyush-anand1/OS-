                           Simulating Virtual Memory Management

A computer programmer assumes a hypothetical situation that their program will have access to the full physical memory . 
Thus, the programs which have to run on the system will almost certainly end up being much larger than what the main memory can hold at a time.
Virtual memory allows us to run programmes much larger than the size of physical memory
Thus, in a Virtual memory system only parts of a code are available in RAM (Main Memory) at any point of time with the rest stored in the non-volatile secondary storage or disk. 
Most of the time, the pages which are required are present in the physical memory.
The programs are thus divided into chunks called ’pages’. Once in a while however, a page which is requested is not available and thus has to be fetched from the secondary memory. 
This is called a ’page fault’

So, Operating Systems effectively give the programs an expanded address space to work in with the OS having
to take the responsibility of handling the added complexity involved. 
This is accomplished using data structures called page tables which map the virtual addresses to their actual physical storages (page frames).

Our main aim is to catch the page faults generated by our programme find out the reason for the page faults 
and then accordingly take the necessary action to solvethe page fault

PROCEDURE:

When we want to run a program we will assign its code to the simulated virtual memory. Then we will create
a mapping between the simulated virtual and physical memory.
We maintain a special C data structure called page table to keep track of the mappings between the two sets of pages. 
It also contains the permission bits [Read(R), Write(W), Execute(E) ] assigned to each virtual page.
We set up a page fault handler to trap the page faults.
The page fault can occur due to two reasons:

1. A page requests a procedure for which it does not have the required permission. for e.g a page with read permission attempts to write. 
We handle these faults by making suitable changes in the permission bits
2. The more important cause of a page fault is when the page is not present in the physical memory (in our case the simulated memory). 
We then have to bring in the page from the secondary memory.

In page fault handler, we implement the mechanism whereby if a page is not in the page table then we first need to check if there is an unoccupied frame in the page table.
We keep track of frame occupancy for quickly detecting an empty frame. 
If a frame is empty, the page is read in from the secondary memory and the page map table is modified.

If no frame is empty then some page has to be evicted for bringing in the new page. 
The question of which page to remove is important and several algorithms known as page replacement algorithms
are available which try to minimize the possibility that an evicted page is needed again soon. 
A good page replacement algorithm will lead to lesser page faults in future, less overhead and thus better performance.
We call the necessary page replacement algorithm to replace appropriate page.

PAGE REPLACEMENT ALGORITHMS:

Random page replacement: This is one of the simplest algorithms available. This follows the principle, ”if you don’t have much idea about a process just do things randomly and hope that the problem[here page fault] will occur rarely” 
i.e. if a page fault occurs and a page is to be replaced, then randomly select a page (frame) from the page table and replace it.
It might throw out the most heavily used page too.
But we hope that if the number of pages is pages large enough, then
it will perform okay on an average. Though it will certainly not be optimal.

First in first out (FIFO)- It assumes that what is the oldest page must be the one which is not used recently.
Hence it kicks out the page which came first i.e. the oldest page from the page table.
However, this approach may not be correct at all because an old page may also be the one which is used frequently. 
Therefore, if we replace that page, then it will make the page management inefficient.
Thus, we expect this algorithm to perform poorly.

Least Recently Used (LRU)- This algorithm also considers the time of page usage. 
That is, whenever a page is accessed, it is marked as most recently used. 
This is based on the locality of reference in time - if a page is referenced now then there is more probability of it being referenced again
in the near future rather that a page which was referenced in the past
1. I have used the linked list approach to implement LRU wherein each page is a node in the page list. 
Whenever a page fault occurs, if the page table has an empty frame then a new node for that page is added in the linked list.
2. If we are required to replace a page, then the page at the head of the list is the one which is least recently used and is replaced. 
The new page is stored at the tail of the list indicating that it is the most recently used.
3. Finally if no fault occurs, i.e if the page is already in the linked list, then it is found out and shifted to the tail of the list again indicating that it is the most recently used.

RESULTS:

1.FOCUS TEST PROGRAM:
Number of pages=12
Number of Frames=7
RANDOM: Page Faults:116, Disk Reads:63, Disk Writes:52
FIFO: Page Faults:112, Disk Reads:61, Disk Writes:52
LRU: Page Faults:112, Disk Reads: 61,Disk Writes:51

2.SCAN TEST PROGRAM:
Number of pages=12
Number of Frames=7
RANDOM: Page Faults:113, Disk Reads101, Disk Writes:12
FIFO: Page Faults:164, Disk Reads:132, Disk Writes:12
LRU: Page Faults:144, Disk Reads:132,Disk Writes:12

3.SORT TEST PROGRAM:
Number of pages=12
Number of Frames=7
RANDOM: Page Faults:85, Disk Reads:48, Disk Writes:35
FIFO: Page Faults:84, Disk Reads:48, Disk Writes:36
LRU: Page Faults:84, Disk Reads:48, Disk Writes:36

In results, we conclude that LRU always performs either equally well or even better than FIFO.
